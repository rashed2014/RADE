{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12b79728-3f1f-4eb4-bfa5-ac743bd7c596",
   "metadata": {},
   "source": [
    "# üß† RADE: Retriever-Augmented Document Entity Extraction\n",
    "\n",
    "This notebook demonstrates how to extract information from trust documents using the **RADE** pipeline.  \n",
    "Each query retrieves relevant chunks using **ColBERT**, then:\n",
    "- Runs a **QA model** (RoBERTa) to extract precise answers\n",
    "- Uses **GLiNER** for entity extraction tied to each query\n",
    "\n",
    "***\n",
    "## Section 1:\n",
    "\n",
    "This section demonstrates how to use the **RADE** (Retriever-Augmented Document Entity Extraction) system for parsing and indexing an unstructured pdf documents\n",
    "\n",
    "RADE integrates:\n",
    "- **ColBERT** for semantic retrieval\n",
    "- **Azure Document Intelligence** for document parsing (PDFs & scanned pages)\n",
    "\n",
    "---\n",
    "\n",
    "## üóÇÔ∏è Steps:\n",
    "1. **Initialize RADE** with model names and Azure credentials\n",
    "2. **Add a document** (PDF) ‚Äî scanned or digital\n",
    "3. **Build the ColBERT index**\n",
    "4. **Retrieve top-k relevant pages**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8fbbb645-847d-48a5-8564-f600d5a3d662",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import sys\n",
    "from rade import RADE, RetrievedPage, DocumentPage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d03dd462-d9ad-4aa2-b64b-e216bbbbcb5d",
   "metadata": {},
   "source": [
    "### üîß Step 1 ‚Äì Initialize RADE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74cf6798-403b-439c-9e59-70f2faca64cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device map: {'retrieval': 'cuda:0', 'qa': 'cuda:1'}\n",
      "Initializing retrieval model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/colbert/utils/amp.py:12: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing QA model and entity extraction models...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0d308d83cdc44619148ef34dbc670e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 10 files:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models initialized successfully!\n"
     ]
    }
   ],
   "source": [
    "#initialize\n",
    "from rade import RADE  # assuming you saved it as rade.py\n",
    "rade = RADE()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "625a3f6b-5b03-4ccf-8c32-08b7216c2b89",
   "metadata": {},
   "source": [
    "## üìÑ Step 2 ‚Äì Add a PDF Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c119967-3a4f-4e66-bd3c-d19a3b411d65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÑ Loading document: 1\n"
     ]
    }
   ],
   "source": [
    "# ‚úÖ Define additional QA Queries\n",
    "pdf_path = \"data/living-trust-forms-03_Ileana Hardison Rev Family Trust DTD 05052010.pdf\"\n",
    "\n",
    "rade.add_document(pdf_path, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac47417-b622-475c-9b16-7e4bae35f324",
   "metadata": {},
   "source": [
    "üìö Step 3 ‚Äì Build the Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "98a830f7-cf68-4f77-95e4-53f235475e6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß Building index for 17 pages...\n",
      "\n",
      "\n",
      "[May 08, 19:38:01] #> Note: Output directory .ragatouille/colbert/indexes/living-trust-forms-03_Ileana Hardison Rev Family Trust DTD 05052010.pdf already exists\n",
      "\n",
      "\n",
      "[May 08, 19:38:01] #> Will delete 15 files already at .ragatouille/colbert/indexes/living-trust-forms-03_Ileana Hardison Rev Family Trust DTD 05052010.pdf in 20 seconds...\n",
      "#> Starting...\n",
      "#> Starting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/colbert/utils/amp.py:12: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler()\n",
      "/opt/conda/lib/python3.11/site-packages/colbert/utils/amp.py:15: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  return torch.cuda.amp.autocast() if self.activated else NullContextManager()\n",
      "/opt/conda/lib/python3.11/site-packages/colbert/utils/amp.py:12: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler()\n",
      "/opt/conda/lib/python3.11/site-packages/colbert/utils/amp.py:15: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  return torch.cuda.amp.autocast() if self.activated else NullContextManager()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nranks = 2 \t num_gpus = 2 \t device=1\n",
      "[May 08, 19:38:27] [1] \t\t #> Encoding 18 passages..\n",
      "nranks = 2 \t num_gpus = 2 \t device=0\n",
      "[May 08, 19:38:27] [0] \t\t #> Encoding 20 passages..\n",
      "[May 08, 19:38:27] [1] \t\t avg_doclen_est = 123.32221984863281 \t len(local_sample) = 18\n",
      "[May 08, 19:38:27] [0] \t\t avg_doclen_est = 123.32221984863281 \t len(local_sample) = 20\n",
      "[May 08, 19:38:27] [0] \t\t Creating 1,024 partitions.\n",
      "[May 08, 19:38:27] [0] \t\t *Estimated* 4,686 embeddings.\n",
      "[May 08, 19:38:27] [0] \t\t #> Saving the indexing plan to .ragatouille/colbert/indexes/living-trust-forms-03_Ileana Hardison Rev Family Trust DTD 05052010.pdf/plan.json ..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/colbert/indexing/collection_indexer.py:256: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  sub_sample = torch.load(sub_sample_path)\n",
      "WARNING clustering 4459 points to 1024 centroids: please provide at least 39936 training points\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustering 4459 points in 128D to 1024 clusters, redo 1 times, 20 iterations\n",
      "  Preprocessing in 0.00 s\n",
      "[May 08, 19:38:28] Loading decompress_residuals_cpp extension (set COLBERT_LOAD_TORCH_EXTENSION_VERBOSE=True for more info)...\n",
      "[May 08, 19:38:28] Loading packbits_cpp extension (set COLBERT_LOAD_TORCH_EXTENSION_VERBOSE=True for more info)...\n",
      "[May 08, 19:38:29] Loading decompress_residuals_cpp extension (set COLBERT_LOAD_TORCH_EXTENSION_VERBOSE=True for more info)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/torch/utils/cpp_extension.py:1964: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. \n",
      "If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/torch/utils/cpp_extension.py:1964: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. \n",
      "If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/colbert/indexing/codecs/residual.py:141: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  centroids = torch.load(centroids_path, map_location='cpu')\n",
      "/opt/conda/lib/python3.11/site-packages/colbert/indexing/codecs/residual.py:141: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  centroids = torch.load(centroids_path, map_location='cpu')\n",
      "/opt/conda/lib/python3.11/site-packages/colbert/indexing/codecs/residual.py:142: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  avg_residual = torch.load(avgresidual_path, map_location='cpu')\n",
      "/opt/conda/lib/python3.11/site-packages/colbert/indexing/codecs/residual.py:142: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  avg_residual = torch.load(avgresidual_path, map_location='cpu')\n",
      "/opt/conda/lib/python3.11/site-packages/colbert/indexing/codecs/residual.py:143: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  bucket_cutoffs, bucket_weights = torch.load(buckets_path, map_location='cpu')\n",
      "/opt/conda/lib/python3.11/site-packages/colbert/indexing/codecs/residual.py:143: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  bucket_cutoffs, bucket_weights = torch.load(buckets_path, map_location='cpu')\n",
      "/opt/conda/lib/python3.11/site-packages/torch/utils/cpp_extension.py:1964: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. \n",
      "If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 08, 19:38:29] Loading packbits_cpp extension (set COLBERT_LOAD_TORCH_EXTENSION_VERBOSE=True for more info)...\n",
      "[May 08, 19:38:29] [1] \t\t #> Encoding 18 passages..\n",
      "[0.027, 0.027, 0.026, 0.023, 0.022, 0.027, 0.025, 0.022, 0.025, 0.027, 0.023, 0.029, 0.025, 0.025, 0.026, 0.027, 0.024, 0.023, 0.025, 0.026, 0.026, 0.025, 0.024, 0.026, 0.023, 0.025, 0.025, 0.027, 0.022, 0.024, 0.025, 0.026, 0.029, 0.025, 0.026, 0.023, 0.027, 0.027, 0.026, 0.032, 0.027, 0.023, 0.023, 0.025, 0.027, 0.026, 0.024, 0.027, 0.027, 0.025, 0.025, 0.026, 0.025, 0.024, 0.022, 0.027, 0.029, 0.026, 0.031, 0.026, 0.023, 0.024, 0.027, 0.024, 0.023, 0.026, 0.024, 0.024, 0.024, 0.026, 0.027, 0.025, 0.027, 0.021, 0.027, 0.028, 0.027, 0.026, 0.025, 0.026, 0.027, 0.028, 0.026, 0.027, 0.024, 0.027, 0.025, 0.024, 0.025, 0.03, 0.026, 0.025, 0.028, 0.028, 0.028, 0.026, 0.031, 0.026, 0.027, 0.025, 0.027, 0.03, 0.026, 0.023, 0.029, 0.027, 0.023, 0.025, 0.024, 0.024, 0.023, 0.032, 0.026, 0.025, 0.03, 0.024, 0.027, 0.027, 0.024, 0.023, 0.024, 0.026, 0.026, 0.028, 0.028, 0.027, 0.024, 0.025]\n",
      "[May 08, 19:38:29] [0] \t\t #> Encoding 20 passages..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/torch/utils/cpp_extension.py:1964: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. \n",
      "If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].\n",
      "  warnings.warn(\n",
      "0it [00:00, ?it/s]/opt/conda/lib/python3.11/site-packages/colbert/utils/amp.py:15: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  return torch.cuda.amp.autocast() if self.activated else NullContextManager()\n",
      "1it [00:00, 19.49it/s]\n",
      "/opt/conda/lib/python3.11/site-packages/colbert/utils/amp.py:15: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  return torch.cuda.amp.autocast() if self.activated else NullContextManager()\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]/opt/conda/lib/python3.11/site-packages/colbert/indexing/codecs/residual_embeddings.py:86: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(codes_path, map_location='cpu')\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:00<00:00, 1673.70it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1024/1024 [00:00<00:00, 53893.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 08, 19:38:29] #> Optimizing IVF to store map from centroids to list of pids..\n",
      "[May 08, 19:38:29] #> Building the emb2pid mapping..\n",
      "[May 08, 19:38:29] len(emb2pid) = 4693\n",
      "[May 08, 19:38:29] #> Saved optimized IVF to .ragatouille/colbert/indexes/living-trust-forms-03_Ileana Hardison Rev Family Trust DTD 05052010.pdf/ivf.pid.pt\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[rank0]:[W508 19:38:29.228065512 ProcessGroupNCCL.cpp:1250] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#> Joined...\n",
      "#> Joined...\n",
      "Done indexing!\n",
      "‚úÖ Index built: .ragatouille/colbert/indexes/living-trust-forms-03_Ileana Hardison Rev Family Trust DTD 05052010.pdf\n"
     ]
    }
   ],
   "source": [
    "rade.build_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "273745bf-fe48-4fb1-9e54-6a6c2a42f541",
   "metadata": {},
   "source": [
    "üîç Step 4 ‚Äì Retrieve Top-k Pages for a Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a1d8dfb8-26e7-4770-8958-063381741edc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Retrieving top-3 chunks for query: What is the name of the Trustee of this trust?\n",
      "Loading searcher for index living-trust-forms-03_Ileana Hardison Rev Family Trust DTD 05052010.pdf for the first time... This may take a few seconds\n",
      "[May 08, 19:38:31] #> Loading codec...\n",
      "[May 08, 19:38:31] Loading decompress_residuals_cpp extension (set COLBERT_LOAD_TORCH_EXTENSION_VERBOSE=True for more info)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/colbert/indexing/codecs/residual.py:141: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  centroids = torch.load(centroids_path, map_location='cpu')\n",
      "/opt/conda/lib/python3.11/site-packages/colbert/indexing/codecs/residual.py:142: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  avg_residual = torch.load(avgresidual_path, map_location='cpu')\n",
      "/opt/conda/lib/python3.11/site-packages/colbert/indexing/codecs/residual.py:143: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  bucket_cutoffs, bucket_weights = torch.load(buckets_path, map_location='cpu')\n",
      "/opt/conda/lib/python3.11/site-packages/torch/utils/cpp_extension.py:1964: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. \n",
      "If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 08, 19:38:31] Loading packbits_cpp extension (set COLBERT_LOAD_TORCH_EXTENSION_VERBOSE=True for more info)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/torch/utils/cpp_extension.py:1964: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. \n",
      "If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 08, 19:38:31] #> Loading IVF...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/colbert/search/index_loader.py:33: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ivf, ivf_lengths = torch.load(os.path.join(self.index_path, \"ivf.pid.pt\"), map_location='cpu')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 08, 19:38:31] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:00<00:00, 4202.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 08, 19:38:31] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]/opt/conda/lib/python3.11/site-packages/colbert/indexing/codecs/residual_embeddings.py:86: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(codes_path, map_location='cpu')\n",
      "/opt/conda/lib/python3.11/site-packages/colbert/indexing/codecs/residual_embeddings.py:93: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(residuals_path, map_location='cpu')\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:00<00:00, 275.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . What is the name of the Trustee of this trust?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  2003,  1996,  2171,  1997,  1996, 13209,  1997,\n",
      "         2023,  3404,  1029,   102,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103], device='cuda:0')\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/opt/conda/lib/python3.11/site-packages/colbert/utils/amp.py:15: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  return torch.cuda.amp.autocast() if self.activated else NullContextManager()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÑ Page 1 | Score: 22.97\n",
      "With this purpose, the primary asset management goal for this Living Trust will be the protection of the value of the Property. The secondary asset management goal for this Living Trust is to generate income and growth at a reasonable risk.\n",
      "Trustee\n",
      "2. During the lifetime of the Grantor, and while the Grantor is not Incapacitated, the Grantor will serve as the primary trustee (the \"Primary Trustee\"\n",
      "üìÑ Page 9 | Score: 22.34\n",
      "b. After the death of the Grantor, the Trustee will have the power to appoint one or more individuals or institutions to act as co-Trustee where it is deemed reasonable and in the best overall interest of this Living Trust.\n",
      "c. The Trustee may employ and rely on the advice of experts including, but not limited to, legal counsel, accountants and investment advisors to help in the management of the P\n",
      "üìÑ Page 10 | Score: 22.23\n",
      "NONPUBLIC//FDIC INTERNAL ONLY\n",
      "d. The Trustee may retain, exchange, insure, repair, improve, sell or dispose of any and all personal property belonging to this Living Trust as the Trustee deems reasonable and in the best overall interest of this Living Trust, without liability for loss or depreciation.\n",
      "a. The Trustee may invest, manage, lease, rent, exchange, mortgage, sell, dispose of or give opti\n"
     ]
    }
   ],
   "source": [
    "results = rade.retrieve(\"What is the name of the Trustee of this trust?\", 3)\n",
    "for r in results:\n",
    "    print(f\"üìÑ Page {r.page.page_num} | Score: {r.score:.2f}\")\n",
    "    print(r.page.text[:400])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f4de3b6-e579-4b98-9040-a2d53cc8f6dd",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2af3dd8d-cf8b-49ee-99fb-06b23a992a8a",
   "metadata": {},
   "source": [
    "## Section 2 üîç RADE Trust Document Analyzer -  Entity and QA Extraction from Trust Documents\n",
    "\n",
    "This section supports:\n",
    "- Named Entity Recognition (NER) using GLiNER for labeled entity queries\n",
    "- Question Answering (QA) using RoBERTa for direct questions\n",
    "\n",
    "Each result:\n",
    "- Retrieves top-k chunks via ColBERT\n",
    "- Runs either QA or NER based on the query type\n",
    "- Presents results interactively using arrows to flip through top passages\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e2ea0fd-2408-40a5-98b7-5fbb8f4dbca4",
   "metadata": {},
   "source": [
    "### Step1 üß© ‚Äì Define Query-to-Label Mapping\n",
    "\n",
    "Use the schema as below:\n",
    "\n",
    "```python\n",
    "{\n",
    "  \"Who are the Grantors?\": {\n",
    "    \"type\": \"ner\",\n",
    "    \"labels\": [\"Grantor\", \"Settlor\"]\n",
    "  },\n",
    "  \"Who are the Trustees?\": {\n",
    "    \"type\": \"ner\",\n",
    "    \"labels\": [\"Primary Trustee\", \"Trustee\"]\n",
    "  },\n",
    "  \"Who are the Successor Trustees?\": {\n",
    "    \"type\": \"ner\",\n",
    "    \"labels\": [\"Successor Trustee\"]\n",
    "  },\n",
    "  \"Who are the Beneficiaries?\": {\n",
    "    \"type\": \"ner\",\n",
    "    \"labels\": [\"Primary Beneficiary\", \"Beneficiary\", \"Residuary Beneficiary\"]\n",
    "  },\n",
    "  \"Who are the Successor Beneficiaries?\": {\n",
    "    \"type\": \"ner\",\n",
    "    \"labels\": [\"Successor Beneficiary\", \"Secondary Beneficiary\"]\n",
    "  },\n",
    "  \"What is the name of the trust?\": {\n",
    "    \"type\": \"qa\",\n",
    "    \"labels\": []\n",
    "  },\n",
    "  \"What is the date of the trust?\": {\n",
    "    \"type\": \"qa\",\n",
    "    \"labels\": []\n",
    "  },\n",
    "  \"Is this trust revocable or irrevocable?\": {\n",
    "    \"type\": \"qa\",\n",
    "    \"labels\": []\n",
    "  }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f5191446-5052-4eef-90c3-9e996933cf6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read query file\n",
    "query_file = \"data/query_plan.json\"\n",
    "with open(query_file, \"r\") as j:\n",
    "    query_plan = json.load(j)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c45cc334-4430-4b3e-9d3d-829b4872522b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to use RADE extractive model\n",
    "def extract_entities_per_page(rade, retrieved_pages, labels):\n",
    "    page_entities = {}\n",
    "\n",
    "    for rp in retrieved_pages:\n",
    "        text = rp.page.text.replace(\"\\n\", \" \")\n",
    "        entities = rade.entity_extraction_model.predict_entities(text, labels)\n",
    "        key = f\"{rp.page.doc_name}_page{rp.page.page_num}\"\n",
    "        page_entities[key] = entities\n",
    "\n",
    "    return page_entities\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae11db9-6f99-4da0-85fa-ff9faf548524",
   "metadata": {},
   "source": [
    "## üß† Step 2 ‚Äì Run RADE: Parse + Index + Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "75bba3a9-9f93-4429-a999-a73fe5533a2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Retrieving top-5 chunks for query: Who are the Grantors?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/colbert/utils/amp.py:15: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  return torch.cuda.amp.autocast() if self.activated else NullContextManager()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Retrieving top-5 chunks for query: Who are the Trustees?\n",
      "üîç Retrieving top-5 chunks for query: Who are the Successor Trustees?\n",
      "üîç Retrieving top-5 chunks for query: Who are the Beneficiaries?\n",
      "üîç Retrieving top-5 chunks for query: Who are the Successor Beneficiaries?\n",
      "üîç Retrieving top-5 chunks for query: What is the name of the trust?\n",
      "üîç Retrieving top-5 chunks for query: What is the date of the trust?\n",
      "üîç Retrieving top-5 chunks for query: Is this trust revocable or irrevocable?\n"
     ]
    }
   ],
   "source": [
    "#Run queries and following NER and QA pipelines with Rade\n",
    "query_results = []\n",
    "\n",
    "for query, meta in query_plan.items():\n",
    "    retrieved = rade.retrieve(query, k=5)\n",
    "\n",
    "    if meta[\"type\"] == \"qa\":\n",
    "        qa_result = rade.run_qa_pipeline(\n",
    "            question=query,\n",
    "            retrieved_texts=[\n",
    "                {\n",
    "                    \"content\": rp.page.text,\n",
    "                    \"document_metadata\": {\n",
    "                        \"document\": rp.page.doc_name,\n",
    "                        \"page\": rp.page.page_num\n",
    "                    }\n",
    "                } for rp in retrieved\n",
    "            ]\n",
    "        )\n",
    "        query_results.append({\n",
    "            \"query\": query,\n",
    "            \"type\": \"qa\",\n",
    "            \"labels\": [],\n",
    "            \"results\": retrieved,\n",
    "            \"qa\": qa_result,\n",
    "            \"entities\": {}\n",
    "        })\n",
    "\n",
    "    elif meta[\"type\"] == \"ner\":\n",
    "        retrieved_texts = [\n",
    "            {\n",
    "                \"content\": rp.page.text,\n",
    "                \"document_metadata\": {\n",
    "                    \"document\": rp.page.doc_name,\n",
    "                    \"page\": rp.page.page_num\n",
    "                }\n",
    "            } for rp in retrieved\n",
    "        ]\n",
    "\n",
    "        entity_result = rade.extract_entities_with_gliner(\n",
    "            retrieved_texts=retrieved_texts,\n",
    "            labels=meta[\"labels\"],\n",
    "            threshold=0.3\n",
    "        )\n",
    "\n",
    "        query_results.append({\n",
    "            \"query\": query,\n",
    "            \"type\": \"ner\",\n",
    "            \"labels\": meta[\"labels\"],\n",
    "            \"results\": retrieved,\n",
    "            \"qa\": None,\n",
    "            \"entities\": {\n",
    "                f\"{r['document']}_page{r['page']}\": [\n",
    "                    e for e in entity_result[\"entities\"]\n",
    "                    if e in entity_result[\"entities\"]\n",
    "                ]\n",
    "                for r in entity_result[\"retrieved\"]\n",
    "            }\n",
    "        })\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a24ef3-71c3-418f-8711-7b8f52b0b19f",
   "metadata": {},
   "source": [
    "## Step 3 - Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d011e4ce-14bc-4718-9be6-f7de37b6ca01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import html\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, Markdown, HTML, clear_output\n",
    "\n",
    "def highlight_entities(text: str, entities: list, highlight_answer: str = None) -> str:\n",
    "    \"\"\"\n",
    "    Highlight QA answer and NER entities using bright yellow <mark>.\n",
    "    \"\"\"\n",
    "    text = html.escape(text)\n",
    "\n",
    "    # Highlight QA answer (first)\n",
    "    if highlight_answer:\n",
    "        safe_answer = html.escape(highlight_answer.strip())\n",
    "        if safe_answer and safe_answer in text:\n",
    "            text = text.replace(\n",
    "                safe_answer,\n",
    "                f'<mark style=\"background-color:yellow\" title=\"QA Answer\">{safe_answer}</mark>'\n",
    "            )\n",
    "\n",
    "    # Highlight NER entities\n",
    "    entities = sorted(entities, key=lambda e: -len(e['text']))\n",
    "    for ent in entities:\n",
    "        safe_text = html.escape(ent[\"text\"])\n",
    "        label = html.escape(ent[\"label\"])\n",
    "        score = ent.get(\"score\", None)\n",
    "        tooltip = f\"{label}\" + (f\" ({score:.2f})\" if score else \"\")\n",
    "        text = text.replace(\n",
    "            safe_text,\n",
    "            f'<mark style=\"background-color:yellow\" title=\"{tooltip}\">{safe_text}</mark>'\n",
    "        )\n",
    "\n",
    "    return text\n",
    "\n",
    "\n",
    "def show_query_results(query_result: dict):\n",
    "    query = query_result[\"query\"]\n",
    "    query_type = query_result[\"type\"]\n",
    "    pages = query_result[\"results\"]\n",
    "    entity_map = query_result[\"entities\"]\n",
    "    qa = query_result[\"qa\"]\n",
    "\n",
    "    index = widgets.IntText(value=0, layout=widgets.Layout(width=\"40px\"), disabled=True)\n",
    "    output = widgets.Output()\n",
    "\n",
    "    prev_button = widgets.Button(description=\"‚óÄÔ∏è Prev\", layout=widgets.Layout(width=\"80px\"))\n",
    "    next_button = widgets.Button(description=\"Next ‚ñ∂Ô∏è\", layout=widgets.Layout(width=\"80px\"))\n",
    "    nav_box = widgets.HBox([prev_button, index, next_button])\n",
    "\n",
    "    def render_page(i):\n",
    "        with output:\n",
    "            clear_output(wait=True)\n",
    "            page = pages[i].page\n",
    "            score = pages[i].score\n",
    "            key = f\"{page.doc_name}_page{page.page_num}\"\n",
    "            ents = entity_map.get(key, []) if query_type == \"ner\" else []\n",
    "\n",
    "            display(Markdown(f\"## üîé Query: `{query}`\"))\n",
    "\n",
    "            if query_type == \"qa\":\n",
    "                answer = qa.get(\"answer\", \"[No answer]\")\n",
    "                display(Markdown(f\"### ü§ñ QA Answer: `{answer}`\"))\n",
    "            else:\n",
    "                answer = None  # Not used\n",
    "\n",
    "            display(Markdown(f\"**üìÑ Page {page.page_num} ‚Äî Score: `{score:.2f}` ‚Äî File: `{page.doc_name}`**\"))\n",
    "\n",
    "            highlighted_text = highlight_entities(\n",
    "                text=page.text[:3000],\n",
    "                entities=ents,\n",
    "                highlight_answer=answer\n",
    "            )\n",
    "\n",
    "            display(HTML(f\"<pre style='line-height:1.5;font-family:monospace'>{highlighted_text}</pre>\"))\n",
    "\n",
    "    def on_prev_clicked(_):\n",
    "        if index.value > 0:\n",
    "            index.value -= 1\n",
    "            render_page(index.value)\n",
    "\n",
    "    def on_next_clicked(_):\n",
    "        if index.value < len(pages) - 1:\n",
    "            index.value += 1\n",
    "            render_page(index.value)\n",
    "\n",
    "    prev_button.on_click(on_prev_clicked)\n",
    "    next_button.on_click(on_next_clicked)\n",
    "\n",
    "    display(nav_box, output)\n",
    "    render_page(index.value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a7d230bb-dd7c-405b-b95b-e56eae636acc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22efccfd0089459db87f935b4bf9bbe5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Button(description='‚óÄÔ∏è Prev', layout=Layout(width='80px'), style=ButtonStyle()), IntText(value=‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7499e49776f34c738bb912ef0c7c8a24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6c0a13c55224c78b42eb6e3fa10fa66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Button(description='‚óÄÔ∏è Prev', layout=Layout(width='80px'), style=ButtonStyle()), IntText(value=‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15fc9e0a75f542de889e3f4f5f7b7222",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c418827bd4e42f48674831eac160129",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Button(description='‚óÄÔ∏è Prev', layout=Layout(width='80px'), style=ButtonStyle()), IntText(value=‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "522aa7e432b3436e9656145c7ba723b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60cf536124ae4928ac506a6de2afe683",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Button(description='‚óÄÔ∏è Prev', layout=Layout(width='80px'), style=ButtonStyle()), IntText(value=‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a81818d08f8e4efdbbb94a82b04fabcf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9851f10699bb43ad8b02749ade21a6d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Button(description='‚óÄÔ∏è Prev', layout=Layout(width='80px'), style=ButtonStyle()), IntText(value=‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7b1d5ebfdb347bca6fd98f336b06b8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7ee726a2a77416cb15e020003884ab5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Button(description='‚óÄÔ∏è Prev', layout=Layout(width='80px'), style=ButtonStyle()), IntText(value=‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf8b5083eefe459a985ea70e9fb2b003",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc59a3c19c264badabc213eddf6084a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Button(description='‚óÄÔ∏è Prev', layout=Layout(width='80px'), style=ButtonStyle()), IntText(value=‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22ccd72b708f4bb38756710847f7a70e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c52056518db54ef884dbc42ac04b3de4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Button(description='‚óÄÔ∏è Prev', layout=Layout(width='80px'), style=ButtonStyle()), IntText(value=‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "057eeb66631444329405fb9d6225a195",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for result in query_results:\n",
    "    show_query_results(result)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
